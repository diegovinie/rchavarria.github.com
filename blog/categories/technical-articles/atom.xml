<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: technical articles | R. Chavarria's Blog]]></title>
  <link href="http://rchavarria.github.io/blog/categories/technical-articles/atom.xml" rel="self"/>
  <link href="http://rchavarria.github.io/"/>
  <updated>2016-02-14T19:49:36+01:00</updated>
  <id>http://rchavarria.github.io/</id>
  <author>
    <name><![CDATA[Rub&eacute;n Chavarr&iacute;a]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Artículo técnico: Getting testy]]></title>
    <link href="http://rchavarria.github.io/blog/2015/12/28/getting-testy/"/>
    <updated>2015-12-28T21:33:00+01:00</updated>
    <id>http://rchavarria.github.io/blog/2015/12/28/getting-testy</id>
    <content type="html"><![CDATA[<p><img class="right" style="width: 250px" src="http://rchavarria.github.io/images/2015/getting-testy.svg"/></p>

<p>Dando una vuelta por Twitter descubrí una serie de artículos sobre testing
titulados <a href="http://randycoulman.com/blog/2015/08/04/getting-testy-redux/">Getting testy</a>, de <a href="http://randycoulman.com/">Randy Coulman</a>. Parecían artículos interesantes,
pero era mucha lectura para ser tratada como un blog. Así que decidí leerlo
como si fuera un libro. Aunque un libro cortito.</p>

<p>Es una serie de artículos muy recomendable sobre TDD y cómo escribir buen
software. Trata muchísimos temas relacionados con escribir tests para nuestro
código. Conceptos sencillos y conceptos avanzados. Diferencias entre los dos
estilos principales de hacer TDD. Qué hacer y qué no hacer a la hora de
escribir tests. Y un sinfín de cosas más. Todas interesantísimas.</p>

<!-- more -->


<h2>Frases a destacar</h2>

<blockquote><p>A la hora de tomar decisiones entre dos extremos, el autor se fija en los más
  y en los menos de cada extremo y trata de sintetizar las mejores partes de
  cada uno en algo sobre lo que pueda trabajar</p></blockquote>

<!-- -->


<blockquote><p>Los problemas a la hora de testear son una buena indicación de los problemas
  que encontrará el código cliente de esos mismos APIs</p></blockquote>

<!-- -->


<blockquote><p>Los tests de aceptación nos dicen si vamos a <strong>construir el sistema
  correcto</strong>. Los tests de más bajo nivel nos dicen si vamos a <strong>construir el
  sistema correctamente</strong> (build the right thing, build the thing right)</p></blockquote>

<!-- -->


<blockquote><p>No se recomiendan tests que prueben métodos específicos: se deberían testear
  las responsabilidades, no los métodos</p></blockquote>

<!-- -->


<blockquote><p>Guard the borders, not the hinterlands</p></blockquote>

<!-- -->


<blockquote><p>No escribas el test que te fuerza a escribir el código que tu quieres.
  Escribe el test que fuerza a tu objeto a tener las responsabilidades que
  quieres que tenga</p></blockquote>

<h2>Notas tomadas</h2>

<p><strong>Historia y mecanismos</strong></p>

<p><em>Dobles de tests</em> es una analogía de la idea de la situación en la que en una
película de acción, un doble suplanta al actor profesional en una escena
peligrosa</p>

<p><strong>Filosofía</strong></p>

<p>A la hora de tomar decisiones entre dos extremos, el autor se fija en los más y
en los menos de cada extremo y trata de sintetizar las mejores partes de cada
uno en algo sobre lo que pueda trabajar.</p>

<p>Dos escuelas fundamentales de hacer TDD:</p>

<ol>
<li>Statist, Detroit: se enfocan en los objetos de tu sistema, lo que lleva a
escribir tests basados en estado.</li>
<li>Mockist, Londres: se enfocan en los mensajes enviados en el sistema, lo que
lleva a escribir tests basados en mocks (o dobles de tests).</li>
</ol>


<p><em>Nota: existe un vídeo, de <a href="https://twitter.com/searls">Justin Searls</a>, donde compara detalladamente estas
dos escuelas: <a href="https://www.youtube.com/watch?v=aeX5OXO-w30">Comparación escuelas TDD</a></em></p>

<p>Un proceso ingenioso para añadir tests a código que existe actualmente:</p>

<ol>
<li>Comenta el codigo que quieres probar</li>
<li>Escribe un test que falle</li>
<li>descomenta el mínimo código que haga que ese test pase</li>
<li>Refactorizar y repetir</li>
</ol>


<p>No tengas miedo a borrar tests. Es más, hay ocasiones en las que querrás
escribir tests para después borrarlos. En ocasiones, cuando estás escribiendo
un algoritmo complejo, querrás escribir tests para las partes que más tarde
serán privadas. Necesitas probar esos pasos intermedios que te lleven a la
solución. Más tarde, cuando hagas esas partes privadas, podrás borrar los tests
<em>temporales</em>.</p>

<p><strong>Funciones</strong></p>

<p>Deja que los tests guíen tu diseño, especialmente la API pública de tus
objetos. Los problemas a la hora de testear son una buena indicación de los
problemas que encontrará el código cliente de esos mismos APIs.</p>

<p>Haz que cada test <em>se pague</em> a sí mismo. Los tests cuestan tiempo y dinero de
ejecutar y mantener. No escribas tests que no añadan suficiente valor para
sobrepasar esos costes. O escríbelos hasta que consigas tener el código que
buscas. Luego, bórralos.</p>

<p><strong>Abstracciones</strong></p>

<p>Cuando crees abstracciones en tu código, es importante elegir aquellas que son
de alguna utilidad. Muchas veces escogemos las abstracciones equivocadas y eso
hace nuestro código más confuso para los que vendrán después de nosotros. Esto
me recuerda a una charla de Sandi Metz, en la que recomendaba algo de
duplicación en lugar de una mala abstracción o mala legibilidad
(<a href="http://rchavarria.github.io/blog/2015/10/18/charla-tecnica-all-the-little-things/">All the little things</a>)</p>

<p><strong>Capas</strong></p>

<p>Los tests de aceptación nos dicen si vamos a <strong>construir el sistema correcto</strong>.
Los tests de más bajo nivel nos dicen si vamos a <strong>construir el sistema
correctamente</strong> (build the right thing, build the thing right)</p>

<p><strong>Aceptación</strong></p>

<p>En la mayoría de los sistemas, los tests de la capa más externa son los tests
más lentos que tenemos. Así pues, queremos cuantos menos de ellos mejor, que no
es lo mismo que decir que no los queremos en absoluto.</p>

<p>Cuando usamos una herramienta como Cucumber of Fitnesse, deberíamos ser capaces
de portar nuestra aplicación a un lenguaje de programación completemante
diferente y seguir manteniendo estos tests. Es decir, los tests de aceptación
deben tener su propio lenguaje, el del negocio, el del dominio del cliente que
va a usar el software.</p>

<p>Cuando estés escribiendo tests para la capa más externa de tu sistema,
pregúntate continuamente si esos tests sobrevivirian si cambias
signficativamente la implementación del sistema que están probando.</p>

<p><strong>Outside-in</strong></p>

<p>Si sientes la necesidad de testear detalles internos de una clase,
probablemente es que hay un objeto que está intentando <em>salir</em>.</p>

<p>Trata de no limitar tus pensamientos a los objetos que ya tienes. No tengas
miedo de introducir nuevos objectos si eso mejora el diseño.</p>

<p><strong>APIs</strong></p>

<p>Para aislarnos de sistemas externos (normalmente escritos por terceros),
debemos ocultar el servicio detrás de un interfaz que definamos y controlemos
nosotros.</p>

<p>No se recomiendan tests que prueben métodos específicos: se deberían testear
las responsabilidades, no los métodos. Los detalles de implementación deberían
estar fuera de los tests.</p>

<p><strong>Pasos</strong></p>

<p>Generalmente, es mejor hacer todo el saneamiento, validaciones y
normalizaciones en los bordes del sistema. Protege las fronteras, no el
interior (Guard the borders, not the hinterlands).</p>

<p><strong>¿Por qué?</strong></p>

<p>Por cada verificación que quieras escribir, pregúntate el por qué de dicha
verificación. ¿La razón tiene que ver con detalles de implementación o tiene
que ver con responsabilidades esenciales del código que estás probando? Si es
la primera, párate un poco y recapacita. Si es la segunda, probablemente vayas
en la buena dirección.</p>

<p>Cuando realizamos verificaciones sobre el estado de la aplicaión antes de hacer
nada en nuestros tests, estamos comunicando algo al lector del código. Es
preferible hacer esa comunicación en un tests separado antes que hacer esas
verificaciones una y otra vez, lo que nos llevaría a tener duplicación en
muchos tests</p>

<p>Otro caso en el que puede haber valor al realizar <em>verificaciones de setup</em>
(verificaciones antes de hacer el propio test) es en código legacy.</p>

<p>No escribas el test que te fuerza a escribir el código que tu quieres. Escribe
el test que fuerza a tu objeto a tener las responsabilidades que quieres que
tenga.</p>

<p><strong>Dobles de tests</strong></p>

<p>¿Cómo saber si un doble de test es un colaborador o un detalle interno? Podemos
hacernos las siguientes preguntas: ¿está al mismo nivel de abstracción que el
objeto que estoy probando? ¿tiene su propio ciclo de vida? Si es así,
probablemente es un colaborador y estaría bien utilizar un doble de tests. En
otro caso, podría ser un detalle interno de implementación, donde deberíamos
plantearnos seriamente si usar el doble de test o no.</p>

<p><strong>Antipatrones</strong></p>

<p>Un buen test unitario debería responder a las siglas en inglés <a href="http://agileinaflash.blogspot.de/2009/02/first.html">F.I.R.S.T.</a>:
Fast, Isolated, Repeatable, Self-verifying, Timely.</p>

<p><strong>Legacy</strong></p>

<p>Al escribir tests para código legacy, no nos debería importar si el código está
dando la respuesa correcta. Solo nos interesa si el código está dando la
<strong>misma</strong> respuesta que antes de realizar los cambios.</p>
]]></content>
  </entry>
  
</feed>
